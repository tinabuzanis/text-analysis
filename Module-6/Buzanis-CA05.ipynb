{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5128b07-ae27-4493-a427-b3be2e15a9b6",
   "metadata": {},
   "source": [
    "### CODE TAKEN FROM Test-Classification.ipynb :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62f84fce-4400-42bf-b2f3-f42fa84d2fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use a lot of packages from sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import html \n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06af3d0e-cfc7-422e-96c8-3a209e122ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df setup\n",
    "\n",
    "file = '../blueprints-text/data/jdt-bugs-dataset/eclipse_jdt.csv.gz' ### real location\n",
    "df = pd.read_csv(file)\n",
    "df = df[['Title', 'Description', 'Priority']].dropna()\n",
    "df['text'] = df['Title'] + ' ' + df['Description']\n",
    "df = df.drop(columns=['Title', 'Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12428597-eba8-4e2c-92bc-44edd31422ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning text\n",
    "def clean(text):\n",
    "    # convert html escapes like &amp; to characters.\n",
    "    text = html.unescape(text) \n",
    "    # tags like <tab>\n",
    "    text = re.sub(r'<[^<>]*>', ' ', text)\n",
    "    # markdown URLs like [Some text](https://....)\n",
    "    text = re.sub(r'\\[([^\\[\\]]*)\\]\\([^\\(\\)]*\\)', r'\\1', text)\n",
    "    # text or code in brackets like [0]\n",
    "    text = re.sub(r'\\[[^\\[\\]]*\\]', ' ', text)\n",
    "    # standalone sequences of specials, matches &# but not #cool\n",
    "    text = re.sub(r'(?:^|\\s)[&#<>{}\\[\\]+|\\\\:-]{1,}(?:\\s|$)', ' ', text)\n",
    "    # standalone sequences of hyphens like --- or ==\n",
    "    text = re.sub(r'(?:^|\\s)[\\-=\\+]{2,}(?:\\s|$)', ' ', text)\n",
    "    # sequences of white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "df['text'] = df['text'].apply(clean)\n",
    "df = df[df['text'].str.len() > 50]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'],\n",
    "                                                    df['Priority'],\n",
    "                                                    test_size=0.2, ### 80-20 train-test split\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df['Priority'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "201fb709-5546-4c48-af96-763bc1c87eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 4000 bug reports with priority P3 \n",
    "df_P3 = df[df['Priority'] == 'P3'].sample(n=4000, random_state=123)\n",
    "\n",
    "# Create a separate dataframe containing all other bug reports\n",
    "df_Rest = df[df['Priority'] != 'P3']\n",
    "\n",
    "# Concatenate the two dataframes to create the new balanced bug reports dataset\n",
    "df_balanced = pd.concat([df_Rest, df_P3])\n",
    "\n",
    "df_new = df_balanced[['text', 'Priority']]\n",
    "df_new = df_new.dropna()\n",
    "\n",
    "# Step 1 - Data Preparation\n",
    "\n",
    "df_new['text'] = df_new['text'].apply(clean)\n",
    "\n",
    "# Step 2 - Train-Test Split\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(df_new['text'],\n",
    "                                                    df_new['Priority'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df_new['Priority'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509277ae-69b2-47fe-9576-bbdf7dea1896",
   "metadata": {},
   "source": [
    "### MY CODE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66630348-3216-479c-ba9c-e706785ed7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "unbalanced_all = df['Priority'] # all priority values from the unbalanced df\n",
    "unbalanced_train = y_train # training priority vals from unbalanced df\n",
    "\n",
    "balanced_all = df_new['Priority'] # all priority vals from balanced df\n",
    "balanced_train = y_train_new # priority vals from training from balanced df \n",
    "\n",
    "# calculates distribution of priority level\n",
    "def calculate_distribution(datasets):\n",
    "    res = []\n",
    "    for data in datasets: # do all datasets at once \n",
    "        # get last char in priority (as there are < 10 priorities)\n",
    "        # turn list of priorities into an np array and\n",
    "        # get value counts \n",
    "        val_counts = np.bincount(np.array([int(val[-1]) for val in data]))\n",
    "        # divide each value count by the total num of values\n",
    "        # and return all datasets together \n",
    "        res.append(np.array([val / len(data) for val in val_counts]))\n",
    "    return res\n",
    "\n",
    "# calculate kl-divergence\n",
    "def kl_divergence(p, q):\n",
    "    return np.sum(np.where(p != 0, p * np.log(p/q), 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8653d11-33a2-4717-8b3e-38e697ac1105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all four datasets\n",
    "datasets = [unbalanced_all, unbalanced_train, balanced_all, balanced_train]\n",
    "\n",
    "# calculate distributions for each dataset\n",
    "distributions = calculate_distribution(datasets)\n",
    "\n",
    "# remove first value of dist. array, as it is 0\n",
    "distributions = [d[1:] for d in distributions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4093076a-be72-4d44-b85c-9c03f43ed566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kl-divergence of the unbalanced training vs entire unbalanced df\n",
    "q_1 = kl_divergence(*distributions[:2])\n",
    "\n",
    "# kl-divergence of balanced training vs balanced df\n",
    "q_2 = kl_divergence(*distributions[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a2ef2a2-44c1-4598-893e-753530944cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1:  1.6866039547917605e-08\n",
      "Q2:  7.944202426577905e-08\n"
     ]
    }
   ],
   "source": [
    "print(\"Q1: \", q_1)\n",
    "print(\"Q2: \", q_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf2388b-372a-4724-85ed-6669065fbb0f",
   "metadata": {},
   "source": [
    "*Q1 and Q2 are the kl-divergence values that go with questions 1 and 2*\n",
    "\n",
    "1. Yes, the distribution of the training data is close to that of df. This is because the 'stratify' argument is used in train-test-split.\n",
    "\n",
    "2. I assume that in this question, df_balanced is meant to be df_new, as it does not make much sense to use df_balanced in this question. If this is the case, yes, the distributions are similar.\n",
    "\n",
    "3. The selections are proportional to the underlying full datasets, however they are not close to each other. If we compare the unbalanced and balanced datasets, we get much different results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d96f221f-5022-45dd-a87e-97d9382be1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45650157100814154"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_divergence(distributions[0], distributions[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
